{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-10T12:51:59.783836Z",
     "start_time": "2025-06-10T12:51:38.939322Z"
    }
   },
   "source": [
    "import gradio as gr\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T12:52:04.422241Z",
     "start_time": "2025-06-10T12:51:59.809612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load model and processor\n",
    "model_name = \"dima806/deepfake_vs_real_image_detection\"\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)"
   ],
   "id": "65610160acbf7da0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T12:52:05.197012Z",
     "start_time": "2025-06-10T12:52:05.185060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "id2label = {\n",
    "    \"0\": \"fake\",\n",
    "    \"1\": \"real\"\n",
    "}"
   ],
   "id": "d96ea45e3a09aa54",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T12:52:05.228254Z",
     "start_time": "2025-06-10T12:52:05.214432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_image(image):\n",
    "    image = Image.fromarray(image).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1).squeeze().tolist()\n",
    "\n",
    "    prediction = {\n",
    "        id2label[str(i)]: round(probs[i], 3) for i in range(len(probs))\n",
    "    }\n",
    "\n",
    "    return prediction"
   ],
   "id": "39e1fcb0a711a16f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T12:52:05.628441Z",
     "start_time": "2025-06-10T12:52:05.278060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iface = gr.Interface(\n",
    "    fn=classify_image,\n",
    "    inputs=gr.Image(type=\"numpy\"),\n",
    "    outputs=gr.Label(num_top_classes=2, label=\"Deepfake Detection\"),\n",
    "    title=\"UDFD\",\n",
    "    description=\"Upload an image to detect whether it is AI-generated (Fake) or a real photograph (Real).\"\n",
    ")"
   ],
   "id": "49a84af1709b6cc9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T12:52:05.987977Z",
     "start_time": "2025-06-10T12:52:05.661246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    iface.launch()"
   ],
   "id": "3f4eeb6c50f8690f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T12:52:06.066159Z",
     "start_time": "2025-06-10T12:52:06.053303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#todo: Explainability con gradcam, shap o lime per evidenziare porzioni di immagini che possano aver influenzato l'output\n",
    "#todo: La web app finale può contenere l'interfaccia (UI) del modello\n",
    "#todo: Modificare il codice del modello per integrare un modulo di sicurezza per identificare eventuali patter posinous\n",
    "#todo: Etichettare il dataset nostro per eventualmente bilanciarlo con FairSmote\n",
    "#todo: MLOps aggiungere pipeline di addestramento automatico, per esempio dando la possibilità agli utenti di valutare l'output (Va gestito il caricamento delle immagini che vanno salvate sul server), dopo un tot numero di NO si riaddestra (Questa cosa può collegarsi con il modulo di sicurezza). Se l'utente non è collaborativo c'è il checkpointing."
   ],
   "id": "475a5d272785d6eb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
